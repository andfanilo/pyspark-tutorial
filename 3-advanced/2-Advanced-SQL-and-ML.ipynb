{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dac3401f7e517b1cec72732f9437fb58",
     "grade": false,
     "grade_id": "cell-dd54ad0671f620b9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Machine Learning in Spark\n",
    "\n",
    "Following the evolution of Spark, there are two ways to do Machine Learning on Spark :\n",
    "\n",
    "* MLlib, or `spark.mllib`, was the first ML library implemented in the core Spark library and runs on RDDs. As of today, the library is in maintenance mode, but as we did for RDDs vs DataFrames, it is important that we cover some aspects of the older library. MLlib is also the only library that supports training models for Spark Streaming. \n",
    "* ML, or `spark.ml` is now the primary ML library on Spark, and runs on DataFrames. Its API is close to those of other mainstream librairies like scikit-learn.\n",
    "\n",
    "We will dive into both APIs in this notebook, using the `titanic.csv` file for classification purposes on the `Survived` column.\n",
    "\n",
    "_I think at this point of your career, you all know what the [Titanic dataset](https://www.kaggle.com/c/titanic/data) is..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92387c8478a08f6cd442a007010a80ea",
     "grade": false,
     "grade_id": "cell-1e94907f4239a99c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName('lecture-lyon2').setMaster('local[*]')\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8d56e90c8e0a2f67a92b3eaaf5feef3c",
     "grade": false,
     "grade_id": "cell-4374dd3b71e3e1aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import Row\n",
    "from pyspark.mllib.linalg import VectorUDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "527fbbddcd0832714c2618aa70ee0cbd",
     "grade": false,
     "grade_id": "cell-d28fe8378ff439c1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Data preparation\n",
    "\n",
    "Even though MLlib is designed with RDDs and DStreams in focus, for ease of transforming the data we will read the data and convert it to a DataFrame. Afterwards we will build RDDs for training in MLlib, or stay in DataFrame for training in ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c8f2873bc0c500cab02f7e7d484a5e76",
     "grade": false,
     "grade_id": "cell-d2682ed444b1c83c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data = spark.read.format('csv').option('header', 'true').option('inferSchema', 'true').load('../data/titanic.csv')\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2f6b121e284c520dc982f47aa2a64dab",
     "grade": false,
     "grade_id": "cell-ca71837cedb092f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "27af6323e3cbecc226fa71cdd931a8ea",
     "grade": false,
     "grade_id": "cell-1ffea3dfd43c7ce6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "From the first summary statistics, we see that the `Age`, `Cabin` and `Embarked` variables can have null values. Also `PassengerId` and `Ticket` look useless for future predictions.\n",
    "\n",
    "# Question\n",
    "  \n",
    "* Drop `Cabin`, `Ticket` and `PassengerId`\n",
    "* Using `.na.fill` function on a DataFrame :\n",
    "    * For `Age`, replace `None` by the mean value for the column. \n",
    "    * For `Embarked` columns, replace `None` by the most frequent value for the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8981ccf6f3077abd1ad00725d9eb21db",
     "grade": false,
     "grade_id": "cell-852a22563e2c66a2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def replace_na(df):\n",
    "    \"\"\"\n",
    "    Deal with na values, and drop selected columns    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "495eb4f93d97689053c64d07cc38cc68",
     "grade": true,
     "grade_id": "cell-9c65ef235a646501",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "3 points\n",
    "\"\"\"\n",
    "result = replace_na(data)\n",
    "assert float(result.describe().toPandas().loc[2]['Age']) - 13 < 0.1\n",
    "assert int(result.describe().toPandas().loc[0]['Embarked']) == 891\n",
    "assert list(result.toPandas().columns.values) == ['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1de211c78b3973a7f5d921c6b072d06a",
     "grade": false,
     "grade_id": "cell-c720dda0d25f41c5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For the following two questions, we will use [Transformers](https://spark.apache.org/docs/2.2.0/ml-pipeline.html#transformers). Technically, a Transformer implements a method `transform()`, which converts one DataFrame into another, generally by appending one or more columns.\n",
    "\n",
    "Example: \n",
    "\n",
    "```python\n",
    "from pyspark.ml.feature import Binarizer\n",
    "\n",
    "continuousDataFrame = spark.createDataFrame([\n",
    "    (0, 0.1),\n",
    "    (1, 0.8),\n",
    "    (2, 0.2)\n",
    "], [\"id\", \"feature\"])\n",
    "continuousDataFrame.show()\n",
    "\n",
    "binarizer = Binarizer(threshold=0.5, inputCol=\"feature\", outputCol=\"binarized_feature\")\n",
    "binarizedDataFrame = binarizer.transform(continuousDataFrame)\n",
    "print(\"Binarizer output with Threshold = %f\" % binarizer.getThreshold())\n",
    "binarizedDataFrame.show()\n",
    "```\n",
    "\n",
    "Result :\n",
    "\n",
    "```\n",
    "+---+-------+\n",
    "| id|feature|\n",
    "+---+-------+\n",
    "|  0|    0.1|\n",
    "|  1|    0.8|\n",
    "|  2|    0.2|\n",
    "+---+-------+\n",
    "\n",
    "Binarizer output with Threshold = 0.500000\n",
    "+---+-------+-----------------+\n",
    "| id|feature|binarized_feature|\n",
    "+---+-------+-----------------+\n",
    "|  0|    0.1|              0.0|\n",
    "|  1|    0.8|              1.0|\n",
    "|  2|    0.2|              0.0|\n",
    "+---+-------+-----------------+\n",
    "```\n",
    "\n",
    "**Note:** contrary to previous notebooks, I have not imported all of the libraries needed to solve the remaining exercises. When you want to import a library, please import it in the same notebook cell as where you implement your code, otherwise it may impact the automatic grading.\n",
    "\n",
    "# Question\n",
    "\n",
    "Through some regex, the [regex_extract UDF](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF) and [SQLTransformer](https://spark.apache.org/docs/2.2.0/ml-features.html#sqltransformer), get the title of a person from the `Name` column in a `Title` column. Drop the `Name` column afterwards.\n",
    "\n",
    "Example\n",
    "\n",
    "```\n",
    "Braund, Mr. Owen       --> Mr\n",
    "Andria, Doctor. Steve  --> Doctor\n",
    "```\n",
    "\n",
    "_Not a hint: while it is perfectly possible to write a custom UDF to solve this question, it breaks the purpose of using Dataframes for cleaning because UDFs don't benefit from SparkSQL's optimizer engine and have to transform back to Java objects for processing. Spark built-in UDFs don't share this problem._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f63d00d042b0e75410b2cb613b62c616",
     "grade": false,
     "grade_id": "cell-93a47dbea9af3ed9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_civility(df):\n",
    "    \"\"\"\n",
    "    Return dataframe dropping Name and replacing with Title\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aaf4120d9637141e40ac9327d2061d52",
     "grade": true,
     "grade_id": "cell-c98d26534a8b160c",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "4 points\n",
    "\"\"\"\n",
    "result = extract_civility(data)\n",
    "resultCols = result.columns\n",
    "assert 'Name' not in resultCols\n",
    "assert 'Civility' in resultCols\n",
    "assert list(result.select('Civility').distinct().toPandas()['Civility'].sort_values().values) == [\n",
    "    'Capt',\n",
    "    'Col',\n",
    "    'Don',\n",
    "    'Dr',\n",
    "    'Jonkheer',\n",
    "    'Lady',\n",
    "    'Major',\n",
    "    'Master',\n",
    "    'Miss',\n",
    "    'Mlle',\n",
    "    'Mme',\n",
    "    'Mr',\n",
    "    'Mrs',\n",
    "    'Ms',\n",
    "    'Rev',\n",
    "    'Sir',\n",
    "    'the Countess'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "840b8c2bfea63a5ef297d22ad9a756a8",
     "grade": false,
     "grade_id": "cell-263e03090b6d1030",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Question \n",
    "\n",
    "[One hot encode](https://spark.apache.org/docs/2.2.0/ml-features.html#onehotencoder) `Sex`, `Civility` and `Embarked` columns into `SexVec`, `CivilityVec` and `EmbarkedVec`. Don't forget to drop the original columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c6fc89f3c0a93f77ce190d1f08ccd505",
     "grade": false,
     "grade_id": "cell-87b6e00fa578a061",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    \"\"\"\n",
    "    Return dataframe one hot encoding selected columns    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a1700e84915682868d08698e63761e2e",
     "grade": true,
     "grade_id": "cell-2ca43cb570eae17b",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "4 points\n",
    "\"\"\"\n",
    "result = one_hot_encode(extract_civility(data))\n",
    "resultCols = result.columns\n",
    "assert len(resultCols) == 12\n",
    "\n",
    "assert 'SexVec' in resultCols\n",
    "assert 'CivilityVec' in resultCols\n",
    "assert 'EmbarkedVec' in resultCols\n",
    "\n",
    "assert 'Sex' not in resultCols\n",
    "assert 'Civility' not in resultCols\n",
    "assert 'Embarked' not in resultCols\n",
    "\n",
    "assert result.schema['SexVec'].simpleString() == 'SexVec:vector'\n",
    "assert result.schema['CivilityVec'].simpleString() == 'CivilityVec:vector'\n",
    "assert result.schema['EmbarkedVec'].simpleString() == 'EmbarkedVec:vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dab91b6c7834a91ffce574703c292c6a",
     "grade": false,
     "grade_id": "cell-eea586c0506e7fed",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Question\n",
    "\n",
    "Now that we have created all of our numeric features, we need to assemble them into the same column. This is the goal of the [VectorAssembler](https://spark.apache.org/docs/2.2.0/ml-features.html#vectorassembler) transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5d779dc852a40f7ac15d24083cc86a5c",
     "grade": false,
     "grade_id": "cell-72faf34acdca3bb4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feature_assemble(df, featureCols):\n",
    "    \"\"\"\n",
    "    Assemble all features in the featureCols list into one column called 'features'.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "23b7efe52dcc5aeeac6114d27641f39c",
     "grade": true,
     "grade_id": "cell-7ad37566eead3ab5",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "2 points\n",
    "\"\"\"\n",
    "result = feature_assemble(data, ['Pclass', 'SibSp', 'Parch'])\n",
    "assert 'features' in result.columns\n",
    "assert result.schema['features'].simpleString() == 'features:vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8c5df23e64ef240fbe5fb092a63cedf7",
     "grade": false,
     "grade_id": "cell-e0d94dd8381cf171",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "#### All the data preparation has been made. After running the following cell, we can concentrate on running ML modelling.\n",
    "\n",
    "For comparison purposes, let's try a Logistic Regression from MLlib and ML on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec8b4ddc9e87222209060ae5d0d05cdd",
     "grade": false,
     "grade_id": "cell-383133b054ab86e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# prepare the data !\n",
    "features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'SexVec', 'CivilityVec', 'EmbarkedVec']\n",
    "prepared_data = feature_assemble(one_hot_encode(extract_civility(replace_na(data))), features)\n",
    "prepared_data = prepared_data.withColumnRenamed(\"Survived\", \"label\").select(['label', 'features'])\n",
    "train, test = prepared_data.randomSplit([0.75, 0.25], 0)\n",
    "\n",
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8d6bb29333c6f86662eec9374a4ca529",
     "grade": false,
     "grade_id": "cell-e455c33086cadefb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## MLlib - RDD based API\n",
    "\n",
    "We will first use the RDD-based [Logistic Regression](https://spark.apache.org/docs/2.2.0/mllib-linear-methods.html#logistic-regression). The exercise comes into two steps :\n",
    "\n",
    "1. First, you must create a RDD of LabeledPoint(label, features). Also careful as we are using `pyspark.ml.linalg.SparseVector` but the RDD-based API expects `pyspark.mllib.linalg.SparseVector`, so we need to [convert it](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=linearregressionwithsgd#pyspark.mllib.linalg.Vectors.fromML).\n",
    "2. Then you can apply LogisticRegression on it.\n",
    "\n",
    "# Question\n",
    "\n",
    "Train a logistic regression model on the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4ea1f00a84a090feaff75579223363b3",
     "grade": false,
     "grade_id": "cell-3d344e0fc760f3e0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def dataframe_to_labeledpoints(df):\n",
    "    \"\"\"\n",
    "    This function takes the conversion from a DataFrame of columns [label, features] to a RDD of LabeledPoint.    \n",
    "    \"\"\"\n",
    "    from pyspark.mllib.regression import LabeledPoint\n",
    "    from pyspark.mllib.linalg import Vectors\n",
    "    \n",
    "    return df.rdd.map(lambda row: LabeledPoint(row[0], Vectors.fromML(row[1])))\n",
    "\n",
    "def train_mllib_logistic(train):\n",
    "    \"\"\"\n",
    "    Return a MLlib logistic regression trained on a RDD of LabeledPoint. \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a57929d658b4020e0f06871602d04b41",
     "grade": true,
     "grade_id": "cell-b54449b3f1087da2",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "4 points\n",
    "\"\"\"\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "train_rdd = dataframe_to_labeledpoints(train)\n",
    "test_rdd = dataframe_to_labeledpoints(test)\n",
    "model = train_mllib_logistic(train_rdd)\n",
    "\n",
    "predictionAndLabels = test_rdd.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
    "\n",
    "metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
    "assert metrics.areaUnderROC > 0.75  # I managed ~0.8 on my first try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6c51bd15ed342f964c8419cce9892b37",
     "grade": false,
     "grade_id": "cell-0967807fd54e6521",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## ML - DataFrame based API\n",
    "\n",
    "We now compare with using the ML [Logistic regression](https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#binomial-logistic-regression). It should work directly on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8261937d04d9a450c5251a2ee9eed67d",
     "grade": false,
     "grade_id": "cell-50cb55db71381eac",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train_ml_logistic(train):\n",
    "    \"\"\"\n",
    "    Return a MLlib logistic regression trained on a RDD of LabeledPoint. \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7def0348bf2f0ec5fa448f9093668879",
     "grade": true,
     "grade_id": "cell-2cb2116413925f78",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Graded cell\n",
    "\n",
    "3 points\n",
    "\"\"\"\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "model = train_ml_logistic(train)\n",
    "assert model.summary.areaUnderROC > 0.75 # managed 0.87 on my first try\n",
    "\n",
    "predictions = model.transform(test)\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "assert evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"}) > 0.75 # managed 0.88 on my first try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ce916c26c6d960dbca976554f0a31bba",
     "grade": false,
     "grade_id": "cell-cc43fdd28fe66f9b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
